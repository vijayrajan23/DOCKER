DRBD and PCS Cluster
node1 node2
##First assing statics ip address
## assing hostname 
hostnamectl set-hostname code1.test.net
hostnamectl set-hostname code2.test.net
## stop & disable firewall service
systemctl stop firewalld
systemctl disable firewalld
## disable selinux service 
setenforce 0
vim /etc/selinux/config
## add disk partion 
fdisk /dev/sdb
partprobe
## add to hosts entry
echo "192.168.5.55	code1.test.net	code1" | tee -a >> /etc/hosts
echo "192.168.5.56	code2.test.net	code2" | tee -a >> /etc/hosts

## install pcs support packages
  yum install -y pacemaker pcs psmisc policycoreutils-python
## add repo of drbd
       rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org
rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm

## install drdb
       yum install -y kmod-drbd84 drbd84-utils

## install httpd php vsftp mysql-server
      yum install httpd php vsftp mysql-server

### inform to kernal drbd 
   modprobe drbd

### create drdb resouser file
/etc/drbd.d/resource_filename.res

vim /etc/drbd.d/clusterdb.res
# resource resource_filename
resource clusterdb {
  protocol C;
  handlers {
    pri-on-incon-degr "/usr/lib/drbd/notify-pri-on-incon-degr.sh; /usr/lib/drbd/notifyemergency-reboot.sh; echo b > /proc/sysrq-trigger ; reboot -f";
    pri-lost-after-sb "/usr/lib/drbd/notify-pri-lost-after-sb.sh; /usr/lib/drbd/notifyemergency-reboot.sh; echo b > /proc/sysrq-trigger; reboot -f";
    local-io-error "/usr/lib/drbd/notify-io-error.sh; /usr/lib/drbd/notify-emergencyshutdown.sh; echo o > /proc/sysrq-trigger ; halt -f";
    fence-peer "/usr/lib/drbd/crm-fence-peer.sh";
    split-brain "/usr/lib/drbd/notify-split-brain.sh admin@acme.com";
    out-of-sync "/usr/lib/drbd/notify-out-of-sync.sh admin@acme.com";
  }
  startup {
    degr-wfc-timeout 120; # 2 minutes.
    outdated-wfc-timeout 2; # 2 seconds.
  }
  disk {
    on-io-error detach;
  }
  net {
   cram-hmac-alg "sha1";
   shared-secret "clusterdb";
   after-sb-0pri disconnect;
   after-sb-1pri disconnect;
   after-sb-2pri disconnect;
   rr-conflict disconnect;

  }
  syncer {
   rate 150M;
   al-extents 257; #Also Linbit told me so personally. The recommended range for this should be between 7 and 3833. The default value is 127
   on-no-data-accessible io-error;
  }
  on code1.test.net {
    device /dev/drbd0;
    disk /dev/sdb1;
    address 192.168.5.55:7788;
    flexible-meta-disk internal;
  }
 on code2.test.net {
    device /dev/drbd0;
    disk /dev/sdb1;
    address 192.168.5.56:7788;
    meta-disk internal;
  }
  }

## create drbd matedata
drbdadm create-md resource_name
drbdadm create-md clusterdb
## start or up resource
drbdadm up clusterdb

## start the drbd services 
systemctl start drbd
systemctl enable drbd
## sync disck 
drbdadm -- --overwrite-data-of-peer primary clusterdb

crate to two directory
mkdir /mysqldata
mkdir /webdata
## edit lvm configuration file
vim /etc/lvm/lvm.conf
 ## her add disk pration name lin /dev/sdb1
   add:  filter = [ "r|/dev/sdb1|", "r|/dev/disk/*|", "r|/dev/block/*|", "a|.*|" ]
## update the write cache state value put 0
   edit: write_cache_state = 1 to write_cache_state = 0
## update lvmtead vlue put 0
   edit:   use_lvmetad = 1 to  use_lvmetad = 0
## infor to kernale lvm changes
lvmconf --enable-halvm --services --startstopservices

dracut -H -f /boot/initramfs-$(uname -r).img $(uname -r)
after reboot
## set drbd primary node 
drbdadm primary --force resources_name
drbdadm primary --force clusterdb

##start pcs service all node
systemctl start pcsd
systemctl enable pcsd

## create password hacluster
passwd hacluster
 


=================== create LVM pration on primary node (code1)===========================
create the physical	drive  use pvcreate
  pvcreate pv_name
  pvcreate /dev/drbd0
create the volum group
  vgcreate vg_name
  vgcreate drbd_vg /dev/drbd0
create the logical volum 
  lvcreate --name lvm_name --size 2G vg_name
  lvcreate --name mysqldata --size 2G drbd_vg
  lvcreate --name webdata --size 2G drbd_vg

Formate disk partion
  
  mkfs.xfs /dev/drbd_vg/mysqldata
  mkfs.xfs /dev/drbd_vg/webdata


auth funcateio add 

pcs cluster auth node1 node2 -u hacluster 

 pcs cluster auth code1.test.net code2.test.net -u hacluster

pcs cluster setup  --name mycluster code1.test.net code2.test.net

## Stop the secondry node of cluster use this coomd
pcs cluster standby code2.test.net
## check pcs status
pcs status 

 pcs cluster cib drbd_cfg
     pcs -f drbd_cfg resource create drbd_clusterdb ocf:linbit:drbd drbd_resource=clusterdb
     pcs -f drbd_cfg resource master drbd_clusterdb_clone drbd_clusterdb master-max=1 master-node-max=1 clone-max=2 clone-node-max=1 notify=true
     pcs cluster cib-push drbd_cfg
     pcs resource create lvm ocf:heartbeat:LVM volgrpname=drbd_vg
     pcs resource create webfsone Filesystem device="/dev/drbd_vg/mysqldata" directory="/mysql_data" fstype="xfs"
     pcs resource create webfstwo Filesystem device="/dev/drbd_vg/webdata" directory="/web_data" fstype="xfs"
     pcs resource create virtualip ocf:heartbeat:IPaddr2 ip=192.168.5.57 cidr_netmask=24
     pcs resource create webserver ocf:heartbeat:apache configfile=/etc/httpd/conf/httpd.conf statusurl="http://localhost/server-status"
     pcs resource group add servergroup virtualip lvm webfsone webfstwo  webserver
     pcs constraint order promote drbd_clusterdb_clone then start servergroup INFINITY
     pcs constraint colocation add servergroup  with master drbd_clusterdb_clone INFINITY
     pcs resource create ftpserver systemd:vsftpd --group servergroup

## pcs cluster start the secondry node for checking 

     pcs cluster unstandby code2.test.net
 
## agin stop secodry node
    
    pcs cluster standby code2.test.net

 ===============================ADD MYSQL Server===============================================================

stop mysql service on all node

systemctl status mysqld
systemctl stop mysqld
systemctl disable mysqld

### move mysql configuration file to cluster lvm directory (/mysql_data)
     mv /etc/my.cnf /mysql_data/my.cnf
### create directory of data      
     mkdir -p /mysql_data/data
## add the mysql dtat directory and bind address     
     vim /mysql_data/my.cnf
     datadir=/mysql_data/data
     bind-address=0.0.0.0
## mysql db inisteation

   mysql_install_db --no-defaults --datadir=/mysql_data/data
## chage the ownr of mysql_data directory
   chown -R mysql:mysql /mysql_data/


## add pcs resource od dbserver
   pcs resource create dbserver ocf:heartbeat:mysql binary="/usr/sbin/mysqld" config="/mysql_data/my.cnf" datadir="/mysql_data/data" pid="/var/lib/mysql/mysql.pid" socket="/var/lib/mysql/mysql.sock" user="mysql" group="mysql" additional_parameters="--user=mysql" --group servergroup
##start mysql server
    systemc start mysqld
    mysql_secure_installation 
     mysql –h 192.168.5.57 –u root –p
     GRANT ALL ON *.* TO 'root'@'%' IDENTIFIED BY 'MyDBpassword';
     FLUSH PRIVILEGES;
     CREATE DATABASE cluster_db;

  pcs resource defaults resource-stickiness=100
  pcs resource op defaults timeout=240s


     refer:
     http://isardvdi-the-docs-repo.readthedocs.io/en/latest/setups/ha/active_passive/
     http://blog.zorangagic.com/2016/02/drbd.html
     http://avid.force.com/pkb/articles/en_US/Compatibility/Troubleshooting-DRBD-on-MediaCentral#A
     http://sheepguardingllama.com/2011/06/drbd-error-device-is-held-open-by-someone/
  ========================================Split-Brin error====================================================================If you get degraded DRBD with log messages like “Split-Brain detected but unresolved, dropping connection!”, you have to manually resolve split brain situation.

Possible reason for such situation

    You switch all cluster nodes in standby via cluster suite (i.e. pacemaker) at the same time, so you don’t have any active drbd instance running.
    You switch the node, which was in Secondary status in drbd last time, online.
    You switch other nodes online

Result:

#/proc/drbd on the code1
version: 8.4.0 (api:1/proto:86-100)
GIT-hash: 28753f559ab51b549d16bcf487fe625d5919c49c build by gardner@, 2011-12-1
2 23:52:00
 0: cs:StandAlone ro:Secondary/Unknown ds:UpToDate/DUnknown   r-----
    ns:0 nr:0 dw:0 dr:0 al:0 bm:0 lo:0 pe:0 ua:0 ap:0 ep:1 wo:b oos:76

#log message on the code1
Mar  7 15:38:05 node1 kernel: block drbd0: Split-Brain detected but unresolved, dropping connection!

#/proc/drbd on the code2
version: 8.4.0 (api:1/proto:86-100)
GIT-hash: 28753f559ab51b549d16bcf487fe625d5919c49c build by gardner@, 2011-12-1
2 23:52:00
 0: cs:StandAlone ro:Primary/Unknown ds:UpToDate/DUnknown   r-----
    ns:0 nr:0 dw:144 dr:4205 al:5 bm:0 lo:0 pe:0 ua:0 ap:0 ep:1 wo:b oos:100

Manually resolve this split brain situation

Start drbd manually on both nodes

Define one node as secondary and discard data on this

drbdadm secondary all
drbdadm disconnect all
drbdadm -- --discard-my-data connect all

Think about the right node to discard the data, otherwise you can lose some data

Define another node as primary and connect

drbdadm primary all
drbdadm disconnect all
drbdadm connect all

Configure drbd for auto split brain resolving

Place this configuration in drbd.conf on both nodes

net {
  after-sb-0pri discard-zero-changes;
  after-sb-1pri discard-secondary;
  after-sb-2pri disconnect;
}